{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f94330c-4d68-4248-84ff-da748f3e1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "all_bus_details = []  # List to hold all bus details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aca2401-c570-4385-ac58-2eda0f8500ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d9cb9be-022c-453d-95bf-7e35a5bcde56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b17d50f-8fbc-442d-b2a0-56f0ebb3dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getrtclinks():\n",
    "    driver = initialize_driver() # Ensure you have the correct WebDriver installed\n",
    "    driver.get(\"https://www.redbus.in/\")  # Replace with the actual URL\n",
    "    \n",
    "    # Extract all script elements\n",
    "    script_elements = driver.find_elements(By.TAG_NAME, \"script\")\n",
    "    \n",
    "    tc_links = []\n",
    "    \n",
    "    # Pattern to match RTC-like URLs (e.g., beginning with // or specific keywords)\n",
    "    url_pattern = re.compile(r'[\"\\'](//[^\"\\']+|http[^\"\\']+)[\"\\']')\n",
    "    \n",
    "    for script in script_elements:\n",
    "        script_content = script.get_attribute(\"innerHTML\")\n",
    "        if script_content:  # Check if the script content is not empty\n",
    "            matches = url_pattern.findall(script_content)\n",
    "            tc_links.extend(matches)\n",
    "    \n",
    "    # Remove duplicates and format links (e.g., add \"http:\" prefix if missing)\n",
    "    tc_links = list(set([\"http:\" + link if link.startswith(\"//\") else link for link in tc_links]))\n",
    "    \n",
    "    \n",
    "    rtc_pages = [page for page in tc_links if 'rtc' in page.lower()]  #to get all the rtc links\n",
    "    stc_pages = [page for page in tc_links if 'stc' in page.lower()]  #to get all the stc links\n",
    "    filtered_rtc = [item for item in rtc_pages if not ('.png' in item or 'directory' in item or '.svg' in item or 'offer' in item.lower())]  #to filter the rtc links\n",
    "    filtered_stc = [item for item in stc_pages if not ('.png' in item or 'directory' in item or '.svg' in item or 'offer' in item.lower())]  #to filter the stc links\n",
    "    Tran_coopertaion_links=filtered_rtc+filtered_stc\n",
    "    cleaned_Tran_coopertaion_links = [item.rstrip('\\\\') for item in Tran_coopertaion_links]\n",
    "    Tran_coopertaion_links=list(set(cleaned_Tran_coopertaion_links))   #to get all unique transport coopoeration links\n",
    "    driver.quit()\n",
    "    return(Tran_coopertaion_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8760bdd7-10eb-4851-adba-c9f79fb1d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21265a98-a624-4a2a-9c54-ad41874239dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_bus_details(driver, url, route_name, state):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "\n",
    "        states={\"astc\":\"Assam\",\"tnstc\":\"Tamil Nadu\",\"upsrtc\":\"Uttar Pradesh\",\"tsrtc\":\"Telengana\",\"rsrtc\":\"Rajastan\",\"gsrtc\":\"Gujarat\",\n",
    "                \"apsrtc\":\"Andhra Pradesh\",\"jksrtc\":\"Jammu & Kashmir\",\"hrtc\":\"Haryana\",\"south-bengal-state-transport-corporation-sbstc\":\"West Bengal\",\n",
    "                \"puducherry-road-transport-corporation-prtc\":\"Pondicherry\",\"ksrtc-karnataka\":\"Karnataka\",\"ksrtc-kerala\":\"Kerela\"}      \n",
    " \n",
    "        # Extract state from the URL if it's part of the URL\n",
    "        #state = url.split(\"/\")[-1]  # Example: Extracts the last part of the URL after '/'\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "            seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "            \n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text.replace(\"INR \", \"\"),\n",
    "                    \"Seat_Availability\": (''.join(filter(str.isdigit, seat_availability_elements[i].text)) if i < len(seat_availability_elements) \n",
    "                                          else '0'),\n",
    "                    \"State\": states.get(state, \"State not found\")  # Adding state here\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "                \n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"No buses found\")\n",
    "            return []\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b5bcd2-ec31-4849-811a-c3db7886b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to navigate through pages\n",
    "def navigate_through_pages(URL):\n",
    "    \"\"\"Navigate through pages and scrape bus routes and details.\"\"\"\n",
    "    global all_bus_details\n",
    "\n",
    "    try:\n",
    "        driver = initialize_driver()\n",
    "        load_page(driver, URL)\n",
    "        state = URL.split(\"/\")[-1]\n",
    "        # Find total number of pages\n",
    "        try:\n",
    "            page_tabs = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"DC_117_pageTabs\")))\n",
    "            num_pages = len(page_tabs)\n",
    "            print(f\"Total pages found: {num_pages}\")\n",
    "        except Exception as e:\n",
    "            print(\"Bus Route terimnation\")\n",
    "            num_pages = 1\n",
    "        \n",
    "        # Loop through each page\n",
    "        for page in range(1, num_pages + 1):\n",
    "            try:\n",
    "                driver = initialize_driver()\n",
    "                load_page(driver, URL)\n",
    "                print(f\"Scraping page {page}...\")\n",
    "\n",
    "                # Handle pagination for pages > 1\n",
    "                if page > 1:\n",
    "                    # Re-locate pagination element to avoid stale element reference\n",
    "                    pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                        EC.element_to_be_clickable(\n",
    "                            (By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page}']\")\n",
    "                        )\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                    driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "\n",
    "                    # Wait for routes to load\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_all_elements_located((By.CLASS_NAME, \"route\"))\n",
    "                    )\n",
    "\n",
    "                # Scrape routes from the current page\n",
    "                bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "\n",
    "                # Scrape details for each route\n",
    "                for link, name in zip(bus_routes_link, bus_routes_name):\n",
    "                    print(f\"Scraping route: {name}\")\n",
    "                    bus_details = scrape_bus_details(driver, link, name, state)\n",
    "                    if bus_details:\n",
    "                        all_bus_details.extend(bus_details)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error navigating to page {page}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while navigating pages: {e}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b67bfdef-5f18-447c-a2fa-50332e742b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Scrape routes and details from all pages\n",
    "    url = getrtclinks()\n",
    "\n",
    "    for ite in url:\n",
    "        navigate_through_pages(ite)\n",
    "        # Convert the list of dictionaries to a DataFrame\n",
    "        df = pd.DataFrame(all_bus_details)\n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv('bus_details_new.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a4905c3-e906-4007-a207-7667581ee77c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Scrape routes and details from all pages\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[43mgetrtclinks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ite \u001b[38;5;129;01min\u001b[39;00m url:\n\u001b[0;32m      6\u001b[0m         navigate_through_pages(ite)\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36mgetrtclinks\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m tc_links \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Pattern to match RTC-like URLs (e.g., beginning with // or specific keywords)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m url_pattern \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m](//[^\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]+|http[^\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]+)[\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m script \u001b[38;5;129;01min\u001b[39;00m script_elements:\n\u001b[0;32m     14\u001b[0m     script_content \u001b[38;5;241m=\u001b[39m script\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minnerHTML\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
