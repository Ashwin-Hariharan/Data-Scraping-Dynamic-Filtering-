{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3b5bcd2-ec31-4849-811a-c3db7886b22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages found: 3\n",
      "Scraping page 1...\n",
      "Scraping route: Khammam to Hyderabad\n",
      "Scraping route: Hyderabad to Vijayawada\n",
      "Scraping route: Hyderabad to Khammam\n",
      "Scraping route: Hyderabad to Srisailam\n",
      "Scraping route: Karimnagar to Hyderabad\n",
      "Scraping route: Hyderabad to Adilabad\n",
      "Scraping route: Kothagudem to Hyderabad\n",
      "Scraping route: Hyderabad to Mancherial\n",
      "Scraping route: Guntur (Andhra Pradesh) to Hyderabad\n",
      "Scraping route: Godavarikhani to Hyderabad\n",
      "Scraping page 2...\n",
      "Scraping route: Kodad to Hyderabad\n",
      "Scraping route: Hyderabad to Ongole\n",
      "Scraping route: Jagityal to Hyderabad\n",
      "Scraping route: Hyderabad to Nirmal\n",
      "Scraping route: Hyderabad to Guntur (Andhra Pradesh)\n",
      "Scraping route: Hyderabad to Karimnagar\n",
      "Scraping route: Hyderabad to Kothagudem\n",
      "Scraping route: Hyderabad to Bhadrachalam\n",
      "Scraping route: Hyderabad to Sathupally\n",
      "Scraping route: Hyderabad to Warangal\n",
      "Scraping page 3...\n",
      "Scraping route: Hyderabad to Tirupati\n",
      "Scraping route: Hyderabad to Anantapur (andhra pradesh)\n",
      "Scraping route: Hyderabad to Armoor\n",
      "Scraping route: Hyderabad to Godavarikhani\n",
      "Scraping route: Peddapalli (Telangana) to Hyderabad\n",
      "Scraping route: Hyderabad to Kodad\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the website\n",
    "URL = \"https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile\"\n",
    "\n",
    "def initialize_driver():\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "    return driver\n",
    "\n",
    "def load_page(driver, url):\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to scrape bus routes\n",
    "def scrape_bus_routes(driver):\n",
    "    route_elements = driver.find_elements(By.CLASS_NAME, 'route')\n",
    "    bus_routes_link = [route.get_attribute('href') for route in route_elements]\n",
    "    bus_routes_name = [route.text.strip() for route in route_elements]\n",
    "    return bus_routes_link, bus_routes_name\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "\n",
    "            # Find bus item details\n",
    "            try:\n",
    "                bus_name_elements = driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            except:\n",
    "                bus_name_elements = \"NA\"\n",
    "            try:\n",
    "                bus_type_elements = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            except:\n",
    "                bus_type_elements = \"NA\"\n",
    "            try:\n",
    "                departing_time_elements = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            except:\n",
    "                departing_time_elements = \"NA\"\n",
    "            try:\n",
    "                duration_elements = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            except:\n",
    "                duration_elements = \"NA\"\n",
    "            try:\n",
    "                reaching_time_elements = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            except:\n",
    "                reaching_time_elements = \"NA\"\n",
    "            try:\n",
    "                star_rating_elements = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            except:\n",
    "                star_rating_elements = \"NA\"\n",
    "            try:\n",
    "                price_elements = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "            except:\n",
    "                price_elements = \"NA\"\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            try:\n",
    "                seat_availability_elements = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "            except:\n",
    "                seat_availability = \"NA\"\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name_elements)):\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name_elements[i].text,\n",
    "                    \"Bus_Type\": bus_type_elements[i].text,\n",
    "                    \"Departing_Time\": departing_time_elements[i].text,\n",
    "                    \"Duration\": duration_elements[i].text,\n",
    "                    \"Reaching_Time\": reaching_time_elements[i].text,\n",
    "                    \"Star_Rating\": star_rating_elements[i].text if i < len(star_rating_elements) else '0',\n",
    "                    \"Price\": price_elements[i].text.replace(\"INR \", \"\"),\n",
    "                    \"Seat_Availability\": seat_availability_elements[i].text if i < len(seat_availability_elements) else '0',\n",
    "                    \"Bus_Exist\" : \"YES\"\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            bus_details=[]\n",
    "            bus_detail = {\n",
    "                \"Route_Name\" : route_name,\n",
    "                \"Route_Link\" : url,\n",
    "                \"Bus_Name\" : \"NA\",\n",
    "                \"Bus_Type\" : \"NA\",\n",
    "                \"Departing_Time\" : \"NA\",\n",
    "                \"Duration\" : \"NA\",\n",
    "                \"Reaching_Time\" : \"NA\",\n",
    "                \"Star_Rating\" : \"NA\",\n",
    "                \"Price\" : \"NA\",\n",
    "                \"Seat_Availability\" : \"NA\",\n",
    "                \"Bus_Exist\" : \"NO\"\n",
    "            }\n",
    "            bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Function to navigate through pages\n",
    "def navigate_through_pages():\n",
    "    \"\"\"Navigate through pages and scrape bus routes and details.\"\"\"\n",
    "    global all_bus_details\n",
    "\n",
    "    try:\n",
    "        driver = initialize_driver()\n",
    "        load_page(driver, URL)\n",
    "\n",
    "        # Find total number of pages\n",
    "        try:\n",
    "            page_tabs = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CLASS_NAME, \"DC_117_pageTabs\"))\n",
    "            )\n",
    "            num_pages = len(page_tabs)\n",
    "            print(f\"Total pages found: {num_pages}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error locating pagination tabs: {e}\")\n",
    "            num_pages = 1\n",
    "\n",
    "        # Loop through each page\n",
    "        for page in range(1, num_pages + 1):\n",
    "            try:\n",
    "                driver = initialize_driver()\n",
    "                load_page(driver, URL)\n",
    "                print(f\"Scraping page {page}...\")\n",
    "\n",
    "                # Handle pagination for pages > 1\n",
    "                if page > 1:\n",
    "                    # Re-locate pagination element to avoid stale element reference\n",
    "                    pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                        EC.element_to_be_clickable(\n",
    "                            (By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs') and text()='{page}']\")\n",
    "                        )\n",
    "                    )\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                    driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "\n",
    "                    # Wait for routes to load\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_all_elements_located((By.CLASS_NAME, \"route\"))\n",
    "                    )\n",
    "\n",
    "                # Scrape routes from the current page\n",
    "                bus_routes_link, bus_routes_name = scrape_bus_routes(driver)\n",
    "\n",
    "                # Scrape details for each route\n",
    "                for link, name in zip(bus_routes_link, bus_routes_name):\n",
    "                    print(f\"Scraping route: {name}\")\n",
    "                    bus_details = scrape_bus_details(driver, link, name)\n",
    "                    if bus_details:\n",
    "                        all_bus_details.extend(bus_details)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error navigating to page {page}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while navigating pages: {e}\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "navigate_through_pages()\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_bus_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('Telangana_bus_details.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
